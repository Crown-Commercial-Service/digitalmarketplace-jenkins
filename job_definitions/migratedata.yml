---
- job:
    name: "migrate-data"
    display-name: "Migrate data"
    project-type: freestyle
    description: |
      Migrate RDS data from production to another environment.
    parameters:
      - choice:
          name: TARGET_STAGE
          choices:
            - Select one
            - preview
            - staging
    logrotate:
      daysToKeep: 120
      artifactDaysToKeep: 120
    scm:
      - git:
          url: git@github.com:alphagov/digitalmarketplace-aws.git
          credentials-id: github_com_and_gds
          branches:
            - master
          wipe-workspace: false
    wrappers:
      - ansicolor
    builders:
      - shell: |
          #!/bin/bash -xe

          [ -d venv ] || virtualenv venv

          . ./venv/bin/activate
          pip install -e .

          EXPORTDATA_PATH='./dumps/sql/exportdata.sql'
          GDRIVE_EXPORTDATA_FOLDER_ID='{{ jenkins_gdrive_folder_id }}'

          AWS_PROFILE="production" dmaws migratedata production  \
            $TARGET_STAGE $TARGET_STAGE \
            ~/digitalmarketplace-credentials/dmaws-vars-files/$TARGET_STAGE.yml \
            $EXPORTDATA_PATH \
            -f ~/digitalmarketplace-credentials/dmaws-vars-files/production.yml

          # we expect this file to be there after running migratedata
          if ! [ -f "$EXPORTDATA_PATH" ];then
              rm -r ./dumps

              echo "Exiting: can't find the $EXPORTDATA_PATH file." >&2
              exit 1
          fi

          echo "Found $EXPORTDATA_PATH. Archiving..." >&2
          zip ./dumps/sql/exportdata.zip $EXPORTDATA_PATH

          echo "Removing $EXPORTDATA_PATH." >&2
          rm $EXPORTDATA_PATH

          # $GDRIVE_EXPORTDATA_FOLDER_ID is the id of the "/dumps" Google Drive folder
          echo "Sync local file with GDrive sync folder with id '$GDRIVE_EXPORTDATA_FOLDER_ID'." >&2
          /usr/local/bin/gdrive --config "/var/lib/jenkins/.gdrive" sync upload --delete-extraneous ./dumps/sql $GDRIVE_EXPORTDATA_FOLDER_ID

          echo "Removing local ./dumps directory." >&2
          rm -r ./dumps
          exit 0
    publishers:
      - trigger-parameterized-builds:
          - project: notify-slack
            condition: UNSTABLE_OR_WORSE
            predefined-parameters: |
              USERNAME=deploy
              JOB="Data migration"
              ICON=:fire:
              STAGE=production
              STATUS=FAILED
              URL=<${BUILD_URL}consoleFull|${BUILD_DISPLAY_NAME}>
              CHANNEL=#dm-release
          - project: notify-slack
            condition: SUCCESS
            predefined-parameters: |
              USERNAME=deploy
              JOB="Data migration"
              ICON=:rowboat:
              STAGE=$TARGET_STAGE
              STATUS=SUCCESS
              URL=<${BUILD_URL}consoleFull|${BUILD_DISPLAY_NAME}>
              CHANNEL=#dm-release
- job:
    name: "migrate-data-to-staging"
    display-name: "Migrate data to staging"
    project-type: freestyle
    description: |
      Migrate RDS data from production to staging.
    logrotate:
      daysToKeep: 120
      artifactDaysToKeep: 120
    builders:
      - trigger-builds:
        - project: migrate-data
          predefined-parameters: |
            TARGET_STAGE=staging
          block: true
